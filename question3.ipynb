{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fdaff2f-a7bb-4c6d-a810-eba47dbfc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library and load data\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = sklearn.datasets.load_iris()\n",
    "x, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f1dd8ef-a2eb-4f8f-910f-a69935eb60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2. Split the dataset into a training set and a test\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.2,random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c79428-e9af-4958-8653-200b344dc789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with manhattan distance metric: \n",
      "[[11  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0  7]]\n",
      "Accuracy with manhattan distance metric: 0.97%\n",
      "\n",
      "Confusion Matrix with euclidean distance metric: \n",
      "[[11  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0  7]]\n",
      "Accuracy with euclidean distance metric: 0.97%\n",
      "\n",
      "Confusion Matrix with cosine distance metric: \n",
      "[[11  0  0]\n",
      " [ 0  9  3]\n",
      " [ 0  0  7]]\n",
      "Accuracy with cosine distance metric: 0.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 3.1.Run K-NN on the Iris dataset with K=3 with \n",
    "for x in ['manhattan', 'euclidean', 'cosine']:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3, metric=x)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    print(\"Confusion Matrix with {} distance metric: \\n{}\".format(x,confusion_matrix(y_test, y_pred)))\n",
    "    print(\"Accuracy with {} distance metric: {:.2f}%\\n\".format(x,accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152435c7-9bf1-4a70-b58b-1fb86dfa9b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with manhattan distance metric: \n",
      "[[10  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 10]]\n",
      "Accuracy with manhattan distance metric: 0.93%\n",
      "\n",
      "Confusion Matrix with euclidean distance metric: \n",
      "[[10  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  1 11]]\n",
      "Accuracy with euclidean distance metric: 0.97%\n",
      "\n",
      "Confusion Matrix with cosine distance metric: \n",
      "[[10  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  0 12]]\n",
      "Accuracy with cosine distance metric: 1.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 3.1.Run K-NN on the Iris dataset with K=3 with KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "for m, n in kf.split(iris.data):\n",
    "    x_train, x_test = iris.data[m], iris.data[n]\n",
    "    y_train, y_test = iris.target[m], iris.target[n]\n",
    "for x in ['manhattan', 'euclidean', 'cosine']:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3, metric=x)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    print(\"Confusion Matrix with {} distance metric: \\n{}\".format(x,confusion_matrix(y_test, y_pred)))\n",
    "    print(\"Accuracy with {} distance metric: {:.2f}%\\n\".format(x,accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d20abedb-49c0-417b-92ed-2912647d18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1, accuracy = 0.960\n",
      "K = 2, accuracy = 0.953\n",
      "K = 3, accuracy = 0.980\n",
      "K = 4, accuracy = 0.980\n",
      "K = 5, accuracy = 0.980\n",
      "K = 6, accuracy = 0.973\n",
      "K = 7, accuracy = 0.960\n",
      "K = 8, accuracy = 0.973\n",
      "K = 9, accuracy = 0.967\n",
      "K = 10, accuracy = 0.967\n",
      "Best number of neighbors: 3\n",
      "Final accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "# Question 3.2. Find the best number of neighbours using k-fold cross validation\n",
    "k_values = [1, 2, 3,4,5,6,7,8,9,10]\n",
    "best_acc = 0\n",
    "best_k = 0\n",
    "for k in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "    scores = cross_val_score(knn, iris.data, iris.target, cv=5)\n",
    "    accuracy = scores.mean()\n",
    "    print(\"K = %d, accuracy = %.3f\" % (k, accuracy))\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best number of neighbors: {}\".format(best_k))\n",
    "print(\"Final accuracy: {:.2f}%\".format(best_acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b552f61-2a03-448f-bd54-2a24b1a5e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with polynomial kernel C=0.001, Mean Sub-Train Loss on Train Data is: 1.3629629629629627 \n",
      "with polynomial kernel C=0.001, Mean Validation Loss on Train Data is: 1.5\n",
      "with polynomial kernel C=0.001, Mean Train Loss on Train Data is: 1.376666666666667\n",
      "with polynomial kernel C=0.001, Mean Test Loss on Test Data is: 1.56\n",
      "with polynomial kernel C=0.001, Mean accuracy on Test Data is: 0.32\n",
      "with polynomial kernel C=0.1, Mean Sub-Train Loss on Train Data is: 0.05185185185185185 \n",
      "with polynomial kernel C=0.1, Mean Validation Loss on Train Data is: 0.041666666666666664\n",
      "with polynomial kernel C=0.1, Mean Train Loss on Train Data is: 0.05083333333333334\n",
      "with polynomial kernel C=0.1, Mean Test Loss on Test Data is: 0.006666666666666666\n",
      "with polynomial kernel C=0.1, Mean accuracy on Test Data is: 0.9933333333333334\n"
     ]
    }
   ],
   "source": [
    "# Question 4.1.train SVM's with different hyperparameter\n",
    "# Split the dataset into a training set and a test\n",
    "#x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.2,random_state=12345)\n",
    "#for x in [0.001, 0.1, 1]     # for Linear Kernel\n",
    "for x in [0.001, 0.1]:        # for Poly Kernel\n",
    "    #model = SVC(C=x, kernel='linear')    # for Linear Kernel\n",
    "    model = SVC(C=x, kernel='poly', degree=2)    # for Poly Kernel\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=12345)\n",
    "    cv_scores = []\n",
    "    cv_train_losses = []\n",
    "    cv_train2_losses = []\n",
    "    cv_val_losses = []\n",
    "    cv_test_losses = []\n",
    "    for m, n in kf.split(x_train):\n",
    "        x_train_fold, x_val_fold = x_train[m], x_train[n]\n",
    "        y_train_fold, y_val_fold = y_train[m], y_train[n]\n",
    "        model.fit(x_train_fold, y_train_fold)\n",
    "        # predict and loss for train and validation in train data\n",
    "        y_pred_train = model.predict(x_train_fold)\n",
    "        loss_train = mean_squared_error(y_train_fold, y_pred_train)\n",
    "        cv_train_losses.append(loss_train)\n",
    "        y_pred_val = model.predict(x_val_fold)\n",
    "        loss_val = mean_squared_error(y_val_fold, y_pred_val)\n",
    "        cv_val_losses.append(loss_val)\n",
    "        # predict and loss for train -The sum of Train and validation on the Kfold\n",
    "        y_pred_train2 = model.predict(x_train)\n",
    "        loss_train2 = mean_squared_error(y_train, y_pred_train2)\n",
    "        cv_train2_losses.append(loss_train2)\n",
    "        # Accuracy and MSE for test data set\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        loss_test = mean_squared_error(y_test, y_pred_test)\n",
    "        cv_test_losses.append(loss_test)\n",
    "        acc = accuracy_score(y_test, y_pred_test)\n",
    "        cv_scores.append(acc)\n",
    "    # Compute and print the mean and the cross-validation scores\n",
    "    mean_train_loss = sum(cv_train_losses) / len(cv_train_losses)\n",
    "    mean_val_loss = sum(cv_val_losses) / len(cv_val_losses)\n",
    "    mean_train2_loss = sum(cv_train2_losses) / len(cv_train2_losses)\n",
    "    mean_test_loss = sum(cv_test_losses) / len(cv_test_losses)\n",
    "    mean_cv_score = sum(cv_scores) / len(cv_scores)\n",
    "    print(\"with polynomial kernel C={}, Mean Sub-Train Loss on Train Data is: {} \".format(x, mean_train_loss))\n",
    "    print(\"with polynomial kernel C={}, Mean Validation Loss on Train Data is: {}\".format(x, mean_val_loss))\n",
    "    print(\"with polynomial kernel C={}, Mean Train Loss on Train Data is: {}\".format(x, mean_train2_loss))\n",
    "    print(\"with polynomial kernel C={}, Mean Test Loss on Test Data is: {}\".format(x, mean_test_loss))\n",
    "    print(\"with polynomial kernel C={}, Mean accuracy on Test Data is: {}\".format(x, mean_cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1a3ea90-3d92-4b92-88b1-4633484aad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random classification: 0.36\n",
      "Accuracy of majority classification: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Question 5.1.train simplest baselines, i.e., random classification and majority classification\n",
    "# Random classification with K-fold\n",
    "dummy_clf_random = DummyClassifier(strategy=\"uniform\")\n",
    "scores_random = cross_val_score(dummy_clf_random, iris.data, iris.target, cv=5)\n",
    "accuracy_random = np.mean(scores_random)\n",
    "\n",
    "# Majority classification with K-fold\n",
    "dummy_clf_majority = DummyClassifier(strategy=\"most_frequent\")\n",
    "scores_majority = cross_val_score(dummy_clf_majority, iris.data, iris.target, cv=5)\n",
    "accuracy_majority = np.mean(scores_majority)\n",
    "\n",
    "print(\"Accuracy of random classification: {}\".format(accuracy_random))\n",
    "print(\"Accuracy of majority classification: {}\".format(accuracy_majority))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
